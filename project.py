# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ORCAZ-nzeUYgHBHxeeC8qmD6YcjcDlpR
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense , GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

from glob import glob
import os

data_set_path = r"/content/drive/MyDrive/Colab Notebooks/Processed Images_Fruits"

fruit_name =[]
Images =[]
labels =[]
Quality_category = ['Bad Quality_Fruits','Good Quality_Fruits','Mixed Qualit_Fruits']
for label, category in enumerate(Quality_category):
    category_path = os.path.join(data_set_path, category)
    for fruit_dir in os.listdir(category_path):
        fruit_path = os.path.join(category_path, fruit_dir)
        images = glob(os.path.join(fruit_path, "*.jpg"))
        Images.extend(images)
        fruit_name.extend([fruit_dir]*len(images))
        labels.extend([label] * len(images))

from PIL import Image

data = np.array(labels)
labels = np.array(labels)

df = pd.DataFrame({ 'image_path': Images, 'fruit_name': fruit_name, 'label': labels})

df['fruit_name']=df['fruit_name'].apply(lambda x: x.split('_')[0])

fruit_list=df['fruit_name'].unique()

from sklearn.utils import shuffle

def shuffle_and_sample(group, frac=0.05):
   group = shuffle(group)
   return group.sample(frac=frac)

sampled_df = df.groupby('fruit_name', group_keys=False).apply(shuffle_and_sample)

print(f"Total images in original DataFrame: {len(df)}")
print(f"Total images in sampled DataFrame: {len(sampled_df)}")
print(sampled_df.head(20))

X = sampled_df.drop('label',axis=1)
y = sampled_df['label']

X['Image']= X['image_path'].apply(lambda x: Image.open(x))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

train= np.array(X_train['Image'])
test= np.array(X_test['Image'])

def resize_image(images, width, height):
    resized_images = []
    for image in images:
        image = image.convert('RGB')
        resized_image = image.resize((width, height))
        resized_image = np.array(resized_image)/ 255
        resized_images.append(resized_image)
    return np.array(resized_images)

train = resize_image(train, 224, 224)
test = resize_image(test, 224, 224)

train = tf.image.resize(train, (96, 96))
test = tf.image.resize(test, (96, 96))

train.shape

def build_cnn_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(96, 96, 3)),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(3, activation='softmax')
    ])
    return model

cnn_model = build_cnn_model()
cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

cnn_model.fit(train, y_train, epochs=10, validation_data=(test, y_test))

cnn_loss,cnn_acc = cnn_model.evaluate(test, y_test)
print(f"CNN Loss: {cnn_loss}")
print(f"CNN Accuracy: {cnn_acc}")

y_pred= cnn_model.predict(test)
predicted_labels = np.argmax(y_pred, axis=1)

predicted_labels

def plot_training_history(History,title):
  plt.figure(figsize=(12,4))
  plt.subplot(1,2,1)
  plt.plot(History.history['loss'],label='Training Loss')
  plt.plot(History.history['val_loss'],label='Validation Loss')
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.legend()
  plt.subplot(1,2,2)
  plt.plot(History.history['accuracy'],label='Training Accuracy')
  plt.plot(History.history['val_accuracy'],label='Validation Accuracy')
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.legend()

plot_training_history(cnn_model.fit(train, y_train, epochs=5, validation_data=(test, y_test)),'CNN')

cm = confusion_matrix(y_test, predicted_labels)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Bad Quality',' Good_Quality','Mixed _quality'], yticklabels=['Bad Quality',' Good_Quality','Mixed _quality'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')

print(classification_report(y_test, predicted_labels))

base_model= MobileNetV2(input_shape=(96,96,3),include_top=False,weights='imagenet')
base_model.trainable = False

x=base_model.output
x=GlobalAveragePooling2D()(x)
x= Dense(128,activation="relu")(x)
output = Dense(3, activation='softmax')(x)
transfer_model = Model(inputs=base_model.input, outputs=output)
transfer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
transfer_history = transfer_model.fit(train, y_train, epochs=5, validation_data=(test, y_test))
plot_training_history(transfer_history,'Transfer Learning')

new_model_loss,new_model_acc = transfer_model.evaluate(test, y_test)
print(f"mobile_net Loss: {new_model_loss}")
print(f"mobile_net Accuracy: {new_model_acc}")

new_pred= transfer_model.predict(test)
new_predicted_labels = np.argmax(y_pred, axis=1)

new_predicted_labels

new_cm=confusion_matrix(y_test, new_predicted_labels)

plt.figure(figsize=(8, 6))
sns.heatmap(new_cm, annot=True, fmt='d', cmap='RdPu', xticklabels=['Bad Quality',' Good_Quality','Mixed _quality'], yticklabels=['Bad Quality',' Good_Quality','Mixed _quality'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')

print(classification_report(y_test, new_predicted_labels))

transfer_model.save('new_transfered_Quality_prediction_model.h5')

print(tf.__version__)

cnn_model.save('cnn_Quality_prediction_model.h5')

